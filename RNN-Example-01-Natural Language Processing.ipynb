{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h1><center>Recurrent Neural Network (using Dataset = imdb)</h1>\n",
    "<b><h2><center>Natural Language Processing - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "imdb.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Loading Training and Testing Datasets Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_text_for_training, outputs_for_training = imdb.load_data(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_text_for_testing, outputs_for_testing = imdb.load_data(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Total Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text_in_total = dataset_text_for_training + dataset_text_for_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Suggesting Number of Unique Words to Use by Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_number_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=take_number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Fitting Tokenizer on Total DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data_text_in_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Converting Texts of Training and Test Sets into Integer Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_training = tokenizer.texts_to_sequences(dataset_text_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_testing = tokenizer.texts_to_sequences(dataset_text_for_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Calculating the Number of Integer Tokens in Each Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_number_totals = np.array([len(tokens) for tokens in tokens_training + tokens_testing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Calculating the Maximum Number of Tokens for Each Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_sequence_length = int(np.mean(tokens_number_totals) + 2 * np.std(tokens_number_totals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Padding the Token Sequences to have the Same Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_padded_tokens = pad_sequences(tokens_training, maxlen=maximum_sequence_length, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_padded_tokens = pad_sequences(tokens_testing, maxlen=maximum_sequence_length, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Inverse Mapping of Tokens to Convert them Back into Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_mapping_indices = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_map = dict(zip(inverse_mapping_indices.values(), inverse_mapping_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Helper Funtion to Convert Tokens into Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_tokens):\n",
    "    output_words = [inverse_map[tokens] for tokens in input_tokens if input_tokens !=0]\n",
    "    converted_string = \" \".join(output_words)\n",
    "    return converted_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>An Example of Comparing Original Text to the Text Translated from the Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When I first read Armistead Maupins story I was taken in by the human drama displayed by Gabriel No one and those he cares about and loves. That being said, we have now been given the film version of an excellent story and are expected to see past the gloss of Hollywood...<br /><br />Writer Armistead Maupin and director Patrick Stettner have truly succeeded! <br /><br />With just the right amount of restraint Robin Williams captures the fragile essence of Gabriel and lets us see his struggle with issues of trust both in his personnel life(Jess) and the world around him(Donna).<br /><br />As we are introduced to the players in this drama we are reminded that nothing is ever as it seems and that the smallest event can change our lives irrevocably. The request to review a book written by a young man turns into a life changing event that helps Gabriel find the strength within himself to carry on and move forward.<br /><br />It\\'s to bad that most people will avoid this film. I only say that because the average American will probably think \"Robin Williams in a serious role? That didn\\'t work before!\" PLEASE GIVE THIS MOVIE A CHANCE! Robin Williams touches the darkness we all must find and go through in ourselves to be better people. Like his movie One Hour Photo he has stepped up as an actor and made another quality piece of art.<br /><br />Oh and before I forget, I believe Bobby Cannavale as Jess steals every scene he is in. He has the 1940\\'s leading man looks and screen presence. It\\'s this hacks opinion he could carry his own movie right now!!<br /><br />S~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_text_for_training[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  50,   10,   86,  339,   64,   10,   13,  607,    8,   31,    1,\n",
       "        395,  449, 4380,   31, 5078,   54,   27,    2,  143,   28, 2150,\n",
       "         42,    2, 1358,   12,  109,  301,   73,   25,  146,   75,  358,\n",
       "          1,   19,  318,    4,   32,  320,   64,    2,   23,  862,    5,\n",
       "         63,  509,    1,    4,  369,    7,    7,  563,    2,  164, 2372,\n",
       "         25,  371, 4163,    7,    7,   16,   39,    1,  203, 1120,    4,\n",
       "       8163, 1943, 1858, 2446,    1, 7019, 3258,    4, 5078,    2, 1573,\n",
       "        176,   63,   24, 1708,   16, 1262,    4, 1740,  195,    8,   24,\n",
       "        114, 6641,    2,    1,  181,  183,   87, 5050,    7,    7,   14,\n",
       "         73,   23, 1705,    5,    1, 1887,    8,   11,  449,   73,   23,\n",
       "       1568,   12,  161,    6,  123,   14,    9,  184,    2,   12,    1,\n",
       "       8927, 1560,   67,  665,  260,  468,    1, 7954,    5,  715,    3,\n",
       "        275,  407,   31,    3,  186,  128,  511,   82,    3,  114, 2538,\n",
       "       1560,   12, 1526, 5078,  165,    1, 2095,  748,  313,    5, 1672,\n",
       "         20,    2,  831,  929,    7,    7,   44,    5,   74,   12,   88,\n",
       "         83,   80,  793,   11,   19,   10,   61,  131,   12,   84,    1,\n",
       "        848,  283,   80,  239,  101, 1943, 1858,    8,    3,  600,  214,\n",
       "         12,  154,  158,  159,  591,  197,   11,   17,    3,  574, 1943,\n",
       "       1858, 2531,    1, 2367,   73,   29,  206,  165,    2,  139,  140,\n",
       "          8, 3158,    5,   26,  126,   83,   37,   24,   17,   27,  527,\n",
       "       4806,   28,   45, 9313,   53,   14,   32,  291,    2,   90,  157,\n",
       "        481,  412,    4,  503,    7,    7,  429,    2,  159,   10,  834,\n",
       "         10,  262, 3177,   14, 6641, 2261,  170,  129,   28,    6,    8,\n",
       "         28,   45,    1, 8231,  993,  128,  285,    2,  258, 1308,   44,\n",
       "         11,  664,   28,   98, 1672,   24,  199,   17,  203,  146,    7,\n",
       "          7,  580])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tokens_training[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"when i first read story i was taken in by the human drama displayed by gabriel no one and those he cares about and loves that being said we have now been given the film version of an excellent story and are expected to see past the of hollywood br br writer and director patrick have truly succeeded br br with just the right amount of restraint robin williams captures the fragile essence of gabriel and lets us see his struggle with issues of trust both in his life jess and the world around him donna br br as we are introduced to the players in this drama we are reminded that nothing is ever as it seems and that the smallest event can change our lives the request to review a book written by a young man turns into a life changing event that helps gabriel find the strength within himself to carry on and move forward br br it's to bad that most people will avoid this film i only say that because the average american will probably think robin williams in a serious role that didn't work before please give this movie a chance robin williams touches the darkness we all must find and go through in ourselves to be better people like his movie one hour photo he has stepped up as an actor and made another quality piece of art br br oh and before i forget i believe bobby as jess steals every scene he is in he has the 1940's leading man looks and screen presence it's this opinion he could carry his own movie right now br br s\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(tokens_training[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Embedding Tokens to feed the GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_for_embedding = 8\n",
    "selected_model.add(Embedding(input_dim=take_number_words,\n",
    "                             output_dim=size_for_embedding,\n",
    "                             input_length=maximum_sequence_length,\n",
    "                             name='layer_embedding'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Addition of GRU Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model.add(GRU(units=16, return_sequences=True))\n",
    "selected_model.add(GRU(units=8, return_sequences=True))\n",
    "selected_model.add(GRU(units=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Addition of a Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Compiling Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model.compile(loss='binary_crossentropy',\n",
    "                       optimizer=Adam(lr=1e-3),\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 544, 8)            80000     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, None, 16)          1200      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, None, 8)           600       \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 81,961\n",
      "Trainable params: 81,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "selected_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23750 samples, validate on 1250 samples\n",
      "Epoch 1/3\n",
      "23750/23750 [==============================]23750/23750 [==============================] - 482s 20ms/step - loss: 0.6577 - acc: 0.5907 - val_loss: 0.4574 - val_acc: 0.8104\n",
      "\n",
      "Epoch 2/3\n",
      "23750/23750 [==============================]23750/23750 [==============================] - 472s 20ms/step - loss: 0.4077 - acc: 0.8213 - val_loss: 0.4496 - val_acc: 0.7888\n",
      "\n",
      "Epoch 3/3\n",
      "23750/23750 [==============================]23750/23750 [==============================] - 465s 20ms/step - loss: 0.2868 - acc: 0.8867 - val_loss: 0.3652 - val_acc: 0.8344\n",
      "\n",
      "Wall time: 23min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1ee0ed6d5f8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "selected_model.fit(training_data_padded_tokens,\n",
    "                   outputs_for_training,\n",
    "                   validation_split=0.05,\n",
    "                   epochs=3,\n",
    "                   batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================]25000/25000 [==============================] - 145s 6ms/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation = selected_model.evaluate(testing_data_padded_tokens, outputs_for_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Printing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.12%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_set = selected_model.predict(x=testing_data_padded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_set = predicted_test_set.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_set_class = np.array([1.0 if p>0.5 else 0.0 for p in predicted_test_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>True Clases of the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test_set_class = np.array(outputs_for_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Comparison of Incorrect Predicted and True Classes of Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(predicted_test_set_class != true_test_set_class)\n",
    "incorrect = incorrect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test_set_class[379]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_test_set_class[379]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Adding New Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewText1 = \"This movie is great! I like it because it is very good!\"\n",
    "NewText2 = \"Fantastic movie!\"\n",
    "NewText3 = \"Maybe I do not like this movie.\"\n",
    "NewText4 = \"Meh ...\"\n",
    "NewText5 = \"If I were a drunk teenager then this movie might be good.\"\n",
    "NewText6 = \"Worst movie!\"\n",
    "NewText7 = \"Not a nice movie!\"\n",
    "NewText8 = \"This movie really sucks! Can I get my money back please?\"\n",
    "Texts = [NewText1, NewText2, NewText3, NewText4, NewText5, NewText6, NewText7, NewText8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Converting New Texts into Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_NewText = tokenizer.texts_to_sequences(Texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 17, 6, 78, 10, 37, 9, 84, 9, 6, 52, 49],\n",
       " [799, 17],\n",
       " [273, 10, 77, 21, 37, 11, 17],\n",
       " [],\n",
       " [43, 10, 70, 3, 1942, 2188, 91, 11, 17, 233, 26, 49],\n",
       " [246, 17],\n",
       " [21, 3, 331, 17],\n",
       " [11, 17, 62, 1692, 67, 10, 76, 56, 290, 141, 591]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_NewText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Padding Token Sequences of NewTexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_padded_NewText = pad_sequences(tokens_NewText, maxlen = maximum_sequence_length, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   6,  52,  49],\n",
       "       [  0,   0,   0, ...,   0, 799,  17],\n",
       "       [  0,   0,   0, ...,  37,  11,  17],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0, 246,  17],\n",
       "       [  0,   0,   0, ...,   3, 331,  17],\n",
       "       [  0,   0,   0, ..., 290, 141, 591]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_padded_NewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 544)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_padded_NewText.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Prediction on New Texts Using the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9365637 ],\n",
       "       [0.8564043 ],\n",
       "       [0.2860732 ],\n",
       "       [0.81650347],\n",
       "       [0.23368984],\n",
       "       [0.30014473],\n",
       "       [0.73337275],\n",
       "       [0.09402247]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model.predict(tokens_padded_NewText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Getting Embedded Layer and its Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding_Layer = selected_model.get_layer('layer_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding_Weights = selected_model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding_Weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h2>Tokens and Embedded Weights for a Few Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_for_word_nice = tokenizer.word_index['nice']\n",
    "token_for_word_nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_for_word_terrific = tokenizer.word_index['terrific']\n",
    "token_for_word_terrific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36549115, 0.77727985, 0.25779524, 0.24881174, 0.75840694,\n",
       "       0.5090445 , 0.8220042 , 0.69435525], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding_Weights[token_for_word_nice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06922172,  0.7642933 ,  0.13405271,  0.9164007 ,  0.5210624 ,\n",
       "       -0.22038034,  0.22925146,  0.95140827], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding_Weights[token_for_word_terrific]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h1><center>!---The End---!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
